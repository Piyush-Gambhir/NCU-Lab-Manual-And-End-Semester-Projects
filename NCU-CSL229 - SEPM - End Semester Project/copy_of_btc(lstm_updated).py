# -*- coding: utf-8 -*-
"""Copy of BTC(LSTM_Updated).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16BgiiImFPpXh233ppDVVR_c2nNF1XVcR
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# Reading the file"""

df = pd.read_csv('/content/BTC-USD.csv')
df.head()

df.tail()

df['Date'] = pd.to_datetime(df['Date'])

df.dropna(inplace=True)

# Convert the "Vol." column to float
df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')

# Print the first few rows of the preprocessed data
print(df.head())

# Check for missing or NaN values in the dataset
missing_values = df.isnull().sum()
print("Missing Values:")
print(missing_values)

# Display the first few rows of the dataset
print("\nFirst few rows of the dataset:")
print(df.head())

# Display the shape of the cleaned dataset
print("Shape of cleaned dataset:", df.shape)

"""# Scaling the data"""

from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler

min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))
ds = min_max_scaler.fit_transform(df['Close'].values.reshape(-1, 1))

# Splitting data into train and test sets
train_size = int(len(ds) * 0.7)
test_size = len(ds) - train_size
train = ds[:train_size]
test = ds[train_size:]

print("Train size: ", len(train))
print("Test size: ", len(test))

"""#Train/Test Distribution"""

look_back = 15

dataX, dataY = [], []
for i in range(look_back, train.shape[0]):
    dataX.append(train[i-look_back:i])
    dataY.append(train[i,0])
x_train = np.array(dataX)
y_train = np.array(dataY)

dataX, dataY = [], []
for i in range(look_back, test.shape[0]):
    dataX.append(test[i-look_back:i])
    dataY.append(test[i,0])
x_test = np.array(dataX)
y_test = np.array(dataY)

print("X-Train shape:", x_train.shape)
print("Y-Train shape:", y_train.shape)
print("X-Test shape:", x_test.shape)
print("Y-Test shape:", y_test.shape)

"""## Creating the Model"""

from keras import Sequential
from keras.layers import Dense, Dropout, LSTM
from tensorflow.keras.optimizers import Adam

model = Sequential()
model.add(LSTM(128, activation='relu', input_shape=(x_train.shape[1], 1))) ##1st checkpoint
model.add(Dropout(0.2))

model.add(Dense(1))

adam = Adam(
    learning_rate=0.00001,
    beta_1=0.001,
    beta_2=0.01,
    epsilon=1e-07,
    amsgrad=False,
)

model.compile(loss='mean_squared_error', optimizer='adam')

np.random.seed(7)

model.summary()

"""# Training the model"""

history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=150, batch_size=32, verbose=1)

loss = history.history['loss']
val_loss = history.history['val_loss']

"""#Predicting"""

trainPredict = model.predict(x_train)
testPredict = model.predict(x_test)

print("Train shape:", trainPredict.shape)
print("Test shape:", testPredict.shape)

"""#Inverting Predictions"""

trainPredict = min_max_scaler.inverse_transform(trainPredict)
trainY = min_max_scaler.inverse_transform([y_train])
trainY = trainY.reshape(y_train.shape)

testPredict = min_max_scaler.inverse_transform(testPredict)
testY = min_max_scaler.inverse_transform([y_test])
testY = testY.reshape(y_test.shape)

"""#Root Mean Squared Error"""

from sklearn.metrics import mean_squared_error
from math import sqrt
import math

trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))
print('Train Score: %.2f RMSE' % (trainScore))

testScore = math.sqrt(mean_squared_error(testY, testPredict))
print('Test Score: %.2f RMSE' % (testScore))

"""#Shifting Train and Test Predictions for Plotting"""

trainPredictPlot = np.empty_like(ds)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

testPredictPlot = np.empty_like(ds)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(look_back*2):len(ds), :] = testPredict

"""#Plotting Baseline Predictions"""

plt.figure(figsize=(15,7))
plt.plot(min_max_scaler.inverse_transform(ds))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.legend(["Recorded Price Value", "Test Price Predict", "Train Price Predict" ], loc=2)
plt.ylabel('Price Value')
plt.xlabel('Day')
plt.show()

"""#R2 and Variance Score"""

from sklearn.metrics import r2_score
print("R squared value on Train data:", r2_score(trainY,trainPredict))
print("R squared value on Test data:", r2_score(testY,testPredict))

from sklearn.metrics import explained_variance_score
print("Variance value on Train data:", explained_variance_score(trainY,trainPredict))
print("Variance value on Test data:", explained_variance_score(testY,testPredict))

"""#Predicting for next n days and Visualization"""

x_input = test[len(test)-look_back:].reshape(1,-1)

temp_input=list(x_input)
temp_input=temp_input[0].tolist()

from numpy import array

lst_output=[]
i=0
n=15   # next number of days for which we are predicting
while(i<n):
    x_input.shape

    if(len(temp_input)>look_back):
        x_input=np.array(temp_input[1:])
        x_input=x_input.reshape(1,-1)
        x_input = x_input.reshape((1, look_back, 1))
        yhat = model.predict(x_input, verbose=0)
        temp_input.extend(yhat[0].tolist())
        temp_input=temp_input[1:]
        lst_output.extend(yhat.tolist())
        i=i+1
    else:
        x_input = x_input.reshape((1, look_back,1))
        yhat = model.predict(x_input, verbose=0)
        temp_input.extend(yhat[0].tolist())
        lst_output.extend(yhat.tolist())
        i=i+1


print(lst_output)

day_new=np.arange(1, look_back+1)
day_pred=np.arange(look_back+1, look_back+n+1)

plt.plot(day_new, min_max_scaler.inverse_transform(ds[len(ds)-look_back:]))
plt.plot(day_pred, min_max_scaler.inverse_transform(lst_output))

plt.figure(figsize=(15,7))
df0=ds.tolist()
df0.extend(lst_output)
plt.plot(df0[2500:])

plt.figure(figsize=(15,7))
df0=min_max_scaler.inverse_transform(df0).tolist()
plt.plot(df0)

# serialize model to JSON
model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")