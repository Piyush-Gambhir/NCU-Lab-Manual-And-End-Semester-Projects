{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szAf2VhAYWVj",
        "outputId": "d91d5c53-ff3e-451b-cf57-453156e16c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gradio -q\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import model_from_json\n",
        "import gradio as gr\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAcLMA_PmT2C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import model_from_json\n",
        "\n",
        "def predict_prices(start_date, n_days):\n",
        "    # Load model architecture from JSON file\n",
        "    with open(\"model.json\", \"r\") as json_file:\n",
        "        loaded_model_json = json_file.read()\n",
        "    # Load the model\n",
        "    model = model_from_json(loaded_model_json)\n",
        "    # Load model weights\n",
        "    model.load_weights(\"model.h5\")\n",
        "\n",
        "    # Load your preprocessed data\n",
        "    df = pd.read_csv('/content/BTC-USD.csv')\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df.dropna(inplace=True)\n",
        "    df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')\n",
        "    # Assuming you've already defined look_back\n",
        "    look_back = 15\n",
        "    # Preprocess the start date\n",
        "    start_date = pd.to_datetime(start_date)\n",
        "    # Find the index corresponding to the provided start date\n",
        "    start_index = df[df['Date'] == start_date].index.tolist()[0]\n",
        "    # Extract the relevant portion of the data for prediction\n",
        "    data = df['Close'].values[start_index-look_back:start_index].reshape(-1, 1)\n",
        "    # Scale the data\n",
        "    min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = min_max_scaler.fit_transform(data)\n",
        "    # Prepare input sequences for prediction\n",
        "    x_input = scaled_data.reshape(1, -1)\n",
        "    temp_input = list(x_input[0])\n",
        "    lst_output = []\n",
        "    n = n_days  # next number of days for which we are predicting\n",
        "    i = 0\n",
        "    predicted_prices = []\n",
        "    while(i < n):\n",
        "        if(len(temp_input) > look_back):\n",
        "            x_input = np.array(temp_input[1:])\n",
        "            x_input = x_input.reshape(1, -1)\n",
        "            x_input = x_input.reshape((1, look_back, 1))\n",
        "            yhat = model.predict(x_input, verbose=0)\n",
        "            temp_input.extend(yhat[0].tolist())\n",
        "            temp_input = temp_input[1:]\n",
        "            lst_output.extend(yhat.tolist())\n",
        "            predicted_price = min_max_scaler.inverse_transform(np.array(yhat).reshape(-1, 1))[0][0]\n",
        "            predicted_prices.append(f\"Predicted price for Day {i+1} is {predicted_price:.2f}\")\n",
        "            i += 1\n",
        "        else:\n",
        "            x_input = x_input.reshape((1, look_back, 1))\n",
        "            yhat = model.predict(x_input, verbose=0)\n",
        "            temp_input.extend(yhat[0].tolist())\n",
        "            lst_output.extend(yhat.tolist())\n",
        "            predicted_price = min_max_scaler.inverse_transform(np.array(yhat).reshape(-1, 1))[0][0]\n",
        "            predicted_prices.append(f\"Predicted price for Day {i+1} is {predicted_price:.2f}\")\n",
        "            i += 1\n",
        "    return predicted_prices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFT44HUkgdYo"
      },
      "outputs": [],
      "source": [
        "date_input = gr.Textbox(label = \"Enter Starting date\")\n",
        "days_input = gr.Number(label = \"Enter the number of days\")\n",
        "output = gr.Textbox(label=\"Predicted prices\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "JwOrk73VrDLo",
        "outputId": "299bf246-7737-4c8e-a7a0-e468c05f803b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://499eb855e942e09476.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://499eb855e942e09476.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_prices,\n",
        "    inputs=[date_input, days_input],\n",
        "    outputs=output,\n",
        "    title=\"Bitcoin Price Prediction\",\n",
        "    description=\"Enter the starting date and the number of days to predict Bitcoin prices.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}