{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply different feature encoding schemes on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id |   bin_0 |   bin_1 |   bin_2 | bin_3   | bin_4   | nom_0   | nom_1     | nom_2   | nom_3   | nom_4   | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 | ord_1       | ord_2    | ord_3   | ord_4   | ord_5   |   day |   month |\n",
      "|---:|-------:|--------:|--------:|--------:|:--------|:--------|:--------|:----------|:--------|:--------|:--------|:----------|:----------|:----------|:----------|:----------|--------:|:------------|:---------|:--------|:--------|:--------|------:|--------:|\n",
      "|  0 | 300000 |       0 |       0 |       1 | T       | Y       | Blue    | Triangle  | Axolotl | Finland | Piano   | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 | Novice      | Warm     | j       | P       | be      |     5 |      11 |\n",
      "|  1 | 300001 |       0 |       0 |       0 | T       | N       | Red     | Square    | Lion    | Canada  | Piano   | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 | Master      | Lava Hot | l       | A       | RP      |     7 |       5 |\n",
      "|  2 | 300002 |       1 |       0 |       1 | F       | Y       | Blue    | Square    | Dog     | China   | Piano   | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 | Expert      | Freezing | a       | G       | tP      |     1 |      12 |\n",
      "|  3 | 300003 |       0 |       0 |       1 | T       | Y       | Red     | Star      | Cat     | China   | Piano   | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 | Contributor | Lava Hot | b       | Q       | ke      |     2 |       3 |\n",
      "|  4 | 300004 |       0 |       1 |       1 | F       | N       | Red     | Trapezoid | Dog     | China   | Piano   | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 | Grandmaster | Lava Hot | l       | W       | qK      |     4 |      11 |\n"
     ]
    }
   ],
   "source": [
    "# reading the dataset\n",
    "data = pd.read_csv('kaggle_encoding_challenge_dataset.csv')\n",
    "\n",
    "# printing the first 5 rows of the dataset\n",
    "print(data.head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id | nom_0   | nom_1     | nom_2   | nom_3   | nom_4   | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 | ord_1       | ord_2    | ord_3   | ord_4   | ord_5   |   day |   month |\n",
      "|---:|-------:|:--------|:----------|:--------|:--------|:--------|:----------|:----------|:----------|:----------|:----------|--------:|:------------|:---------|:--------|:--------|:--------|------:|--------:|\n",
      "|  0 | 300000 | Blue    | Triangle  | Axolotl | Finland | Piano   | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 | Novice      | Warm     | j       | P       | be      |     5 |      11 |\n",
      "|  1 | 300001 | Red     | Square    | Lion    | Canada  | Piano   | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 | Master      | Lava Hot | l       | A       | RP      |     7 |       5 |\n",
      "|  2 | 300002 | Blue    | Square    | Dog     | China   | Piano   | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 | Expert      | Freezing | a       | G       | tP      |     1 |      12 |\n",
      "|  3 | 300003 | Red     | Star      | Cat     | China   | Piano   | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 | Contributor | Lava Hot | b       | Q       | ke      |     2 |       3 |\n",
      "|  4 | 300004 | Red     | Trapezoid | Dog     | China   | Piano   | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 | Grandmaster | Lava Hot | l       | W       | qK      |     4 |      11 |\n"
     ]
    }
   ],
   "source": [
    "# dropping not required columns from the dataset (bin_0, bin_1, bin_2, bin_3, bin_4)\n",
    "data.drop(['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4'], axis=1, inplace=True)\n",
    "\n",
    "# printing the first 5 rows of the dataset\n",
    "print(data.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 |   day |   month | nom_0_Blue   | nom_0_Green   | nom_0_Red   | nom_1_Circle   | nom_1_Polygon   | nom_1_Square   | nom_1_Star   | nom_1_Trapezoid   | nom_1_Triangle   | nom_2_Axolotl   | nom_2_Cat   | nom_2_Dog   | nom_2_Hamster   | nom_2_Lion   | nom_2_Snake   | nom_3_Canada   | nom_3_China   | nom_3_Costa Rica   | nom_3_Finland   | nom_3_India   | nom_3_Russia   | nom_4_Bassoon   | nom_4_Oboe   | nom_4_Piano   | nom_4_Theremin   | ord_1_Contributor   | ord_1_Expert   | ord_1_Grandmaster   | ord_1_Master   | ord_1_Novice   | ord_2_Boiling Hot   | ord_2_Cold   | ord_2_Freezing   | ord_2_Hot   | ord_2_Lava Hot   | ord_2_Warm   | ord_3_a   | ord_3_b   | ord_3_c   | ord_3_d   | ord_3_e   | ord_3_f   | ord_3_g   | ord_3_h   | ord_3_i   | ord_3_j   | ord_3_k   | ord_3_l   | ord_3_m   | ord_3_n   | ord_3_o   | ord_4_A   | ord_4_B   | ord_4_C   | ord_4_D   | ord_4_E   | ord_4_F   | ord_4_G   | ord_4_H   | ord_4_I   | ord_4_J   | ord_4_K   | ord_4_L   | ord_4_M   | ord_4_N   | ord_4_O   | ord_4_P   | ord_4_Q   | ord_4_R   | ord_4_S   | ord_4_T   | ord_4_U   | ord_4_V   | ord_4_W   | ord_4_X   | ord_4_Y   | ord_4_Z   | ord_5_AP   | ord_5_Ai   | ord_5_Aj   | ord_5_BA   | ord_5_BE   | ord_5_Bb   | ord_5_Bd   | ord_5_Bn   | ord_5_CL   | ord_5_CM   | ord_5_CU   | ord_5_CZ   | ord_5_Cl   | ord_5_DH   | ord_5_DN   | ord_5_Dc   | ord_5_Dx   | ord_5_Ed   | ord_5_Eg   | ord_5_Er   | ord_5_FI   | ord_5_Fd   | ord_5_Fo   | ord_5_GD   | ord_5_GJ   | ord_5_Gb   | ord_5_Gx   | ord_5_Hj   | ord_5_IK   | ord_5_Id   | ord_5_JX   | ord_5_Jc   | ord_5_Jf   | ord_5_Jt   | ord_5_KR   | ord_5_KZ   | ord_5_Kf   | ord_5_Kq   | ord_5_LE   | ord_5_MC   | ord_5_MO   | ord_5_MV   | ord_5_Mf   | ord_5_Ml   | ord_5_Mx   | ord_5_NV   | ord_5_Nf   | ord_5_Nk   | ord_5_OR   | ord_5_Ob   | ord_5_Os   | ord_5_PA   | ord_5_PQ   | ord_5_PZ   | ord_5_Ps   | ord_5_QM   | ord_5_Qb   | ord_5_Qh   | ord_5_Qo   | ord_5_RG   | ord_5_RL   | ord_5_RP   | ord_5_Rm   | ord_5_Ry   | ord_5_SB   | ord_5_Sc   | ord_5_TR   | ord_5_TZ   | ord_5_To   | ord_5_UO   | ord_5_Uk   | ord_5_Uu   | ord_5_Vf   | ord_5_Vx   | ord_5_WE   | ord_5_Wc   | ord_5_Wv   | ord_5_XI   | ord_5_Xh   | ord_5_Xi   | ord_5_YC   | ord_5_Yb   | ord_5_Ye   | ord_5_ZR   | ord_5_ZS   | ord_5_Zc   | ord_5_Zq   | ord_5_aF   | ord_5_aM   | ord_5_aO   | ord_5_aP   | ord_5_ac   | ord_5_av   | ord_5_bF   | ord_5_bJ   | ord_5_be   | ord_5_cA   | ord_5_cG   | ord_5_cW   | ord_5_ck   | ord_5_cp   | ord_5_dB   | ord_5_dE   | ord_5_dN   | ord_5_dO   | ord_5_dP   | ord_5_dQ   | ord_5_dZ   | ord_5_dh   | ord_5_eG   | ord_5_eQ   | ord_5_eb   | ord_5_eg   | ord_5_ek   | ord_5_ex   | ord_5_fO   | ord_5_fh   | ord_5_gJ   | ord_5_gM   | ord_5_hL   | ord_5_hT   | ord_5_hh   | ord_5_hp   | ord_5_iT   | ord_5_ih   | ord_5_jS   | ord_5_jV   | ord_5_je   | ord_5_jp   | ord_5_kC   | ord_5_kE   | ord_5_kK   | ord_5_kL   | ord_5_kU   | ord_5_kW   | ord_5_ke   | ord_5_kr   | ord_5_kw   | ord_5_lF   | ord_5_lL   | ord_5_ll   | ord_5_lx   | ord_5_mb   | ord_5_mc   | ord_5_mm   | ord_5_nX   | ord_5_nh   | ord_5_oC   | ord_5_oG   | ord_5_oH   | ord_5_oK   | ord_5_od   | ord_5_on   | ord_5_pa   | ord_5_ps   | ord_5_qA   | ord_5_qJ   | ord_5_qK   | ord_5_qP   | ord_5_qX   | ord_5_qo   | ord_5_qv   | ord_5_qw   | ord_5_rZ   | ord_5_ri   | ord_5_rp   | ord_5_sD   | ord_5_sV   | ord_5_sY   | ord_5_sn   | ord_5_su   | ord_5_tM   | ord_5_tP   | ord_5_tv   | ord_5_uJ   | ord_5_uS   | ord_5_ud   | ord_5_us   | ord_5_ut   | ord_5_ux   | ord_5_uy   | ord_5_vK   | ord_5_vq   | ord_5_vy   | ord_5_wu   | ord_5_wy   | ord_5_xP   | ord_5_xy   | ord_5_yN   | ord_5_yY   | ord_5_yc   | ord_5_zU   |\n",
      "|---:|-------:|:----------|:----------|:----------|:----------|:----------|--------:|------:|--------:|:-------------|:--------------|:------------|:---------------|:----------------|:---------------|:-------------|:------------------|:-----------------|:----------------|:------------|:------------|:----------------|:-------------|:--------------|:---------------|:--------------|:-------------------|:----------------|:--------------|:---------------|:----------------|:-------------|:--------------|:-----------------|:--------------------|:---------------|:--------------------|:---------------|:---------------|:--------------------|:-------------|:-----------------|:------------|:-----------------|:-------------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|:-----------|\n",
      "|  0 | 300000 | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 |     5 |      11 | True         | False         | False       | False          | False           | False          | False        | False             | True             | True            | False       | False       | False           | False        | False         | False          | False         | False              | True            | False         | False          | False           | False        | True          | False            | False               | False          | False               | False          | True           | False               | False        | False            | False       | False            | True         | False     | False     | False     | False     | False     | False     | False     | False     | False     | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | True       | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      |\n",
      "|  1 | 300001 | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 |     7 |       5 | False        | False         | True        | False          | False           | True           | False        | False             | False            | False           | False       | False       | False           | True         | False         | True           | False         | False              | False           | False         | False          | False           | False        | True          | False            | False               | False          | False               | True           | False          | False               | False        | False            | False       | True             | False        | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | True      | False     | False     | False     | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | True       | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      |\n",
      "|  2 | 300002 | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 |     1 |      12 | True         | False         | False       | False          | False           | True           | False        | False             | False            | False           | False       | True        | False           | False        | False         | False          | True          | False              | False           | False         | False          | False           | False        | True          | False            | False               | True           | False               | False          | False          | False               | False        | True             | False       | False            | False        | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | True       | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      |\n",
      "|  3 | 300003 | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 |     2 |       3 | False        | False         | True        | False          | False           | False          | True         | False             | False            | False           | True        | False       | False           | False        | False         | False          | True          | False              | False           | False         | False          | False           | False        | True          | False            | True                | False          | False               | False          | False          | False               | False        | False            | False       | True             | False        | False     | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | True       | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      |\n",
      "|  4 | 300004 | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 |     4 |      11 | False        | False         | True        | False          | False           | False          | False        | True              | False            | False           | False       | True        | False           | False        | False         | False          | True          | False              | False           | False         | False          | False           | False        | True          | False            | False               | False          | True                | False          | False          | False               | False        | False            | False       | True             | False        | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | True      | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | False     | True      | False     | False     | False     | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | True       | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      | False      |\n"
     ]
    }
   ],
   "source": [
    "# make a copy of the dataset\n",
    "data_one_hot_encoding = data.copy()\n",
    "\n",
    "# performing one hot encoding on the dataset\n",
    "data_one_hot_encoding = pd.get_dummies(data_one_hot_encoding, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5'])\n",
    "\n",
    "# printing the first 5 rows of the dataset\n",
    "print(data_one_hot_encoding.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id |   nom_0 |   nom_1 |   nom_2 |   nom_3 |   nom_4 | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 | ord_1       | ord_2    | ord_3   | ord_4   | ord_5   |   day |   month |\n",
      "|---:|-------:|--------:|--------:|--------:|--------:|--------:|:----------|:----------|:----------|:----------|:----------|--------:|:------------|:---------|:--------|:--------|:--------|------:|--------:|\n",
      "|  0 | 300000 |       0 |       5 |       0 |       3 |       2 | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 | Novice      | Warm     | j       | P       | be      |     5 |      11 |\n",
      "|  1 | 300001 |       2 |       2 |       4 |       0 |       2 | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 | Master      | Lava Hot | l       | A       | RP      |     7 |       5 |\n",
      "|  2 | 300002 |       0 |       2 |       2 |       1 |       2 | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 | Expert      | Freezing | a       | G       | tP      |     1 |      12 |\n",
      "|  3 | 300003 |       2 |       3 |       1 |       1 |       2 | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 | Contributor | Lava Hot | b       | Q       | ke      |     2 |       3 |\n",
      "|  4 | 300004 |       2 |       4 |       2 |       1 |       2 | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 | Grandmaster | Lava Hot | l       | W       | qK      |     4 |      11 |\n"
     ]
    }
   ],
   "source": [
    "# performing label encoding on the dataset\n",
    "\n",
    "# creating an object of the LabelEncoder class\n",
    "le = LabelEncoder()\n",
    "\n",
    "# make a copy of the dataset\n",
    "data_label_encoding = data.copy()\n",
    "\n",
    "# performing label encoding on the dataset\n",
    "data_label_encoding['nom_0'] = le.fit_transform(data_label_encoding['nom_0'])\n",
    "data_label_encoding['nom_1'] = le.fit_transform(data_label_encoding['nom_1'])\n",
    "data_label_encoding['nom_2'] = le.fit_transform(data_label_encoding['nom_2'])\n",
    "data_label_encoding['nom_3'] = le.fit_transform(data_label_encoding['nom_3'])\n",
    "data_label_encoding['nom_4'] = le.fit_transform(data_label_encoding['nom_4'])\n",
    "\n",
    "# printing the first 5 rows of the dataset\n",
    "print(data_label_encoding.head().to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dummy Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 | ord_1       | ord_2    | ord_3   | ord_4   | ord_5   |   day |   month | nom_0_Green   | nom_0_Red   | nom_1_Polygon   | nom_1_Square   | nom_1_Star   | nom_1_Trapezoid   | nom_1_Triangle   | nom_2_Cat   | nom_2_Dog   | nom_2_Hamster   | nom_2_Lion   | nom_2_Snake   | nom_3_China   | nom_3_Costa Rica   | nom_3_Finland   | nom_3_India   | nom_3_Russia   | nom_4_Oboe   | nom_4_Piano   | nom_4_Theremin   |\n",
      "|---:|-------:|:----------|:----------|:----------|:----------|:----------|--------:|:------------|:---------|:--------|:--------|:--------|------:|--------:|:--------------|:------------|:----------------|:---------------|:-------------|:------------------|:-----------------|:------------|:------------|:----------------|:-------------|:--------------|:--------------|:-------------------|:----------------|:--------------|:---------------|:-------------|:--------------|:-----------------|\n",
      "|  0 | 300000 | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 | Novice      | Warm     | j       | P       | be      |     5 |      11 | False         | False       | False           | False          | False        | False             | True             | False       | False       | False           | False        | False         | False         | False              | True            | False         | False          | False        | True          | False            |\n",
      "|  1 | 300001 | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 | Master      | Lava Hot | l       | A       | RP      |     7 |       5 | False         | True        | False           | True           | False        | False             | False            | False       | False       | False           | True         | False         | False         | False              | False           | False         | False          | False        | True          | False            |\n",
      "|  2 | 300002 | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 | Expert      | Freezing | a       | G       | tP      |     1 |      12 | False         | False       | False           | True           | False        | False             | False            | False       | True        | False           | False        | False         | True          | False              | False           | False         | False          | False        | True          | False            |\n",
      "|  3 | 300003 | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 | Contributor | Lava Hot | b       | Q       | ke      |     2 |       3 | False         | True        | False           | False          | True         | False             | False            | True        | False       | False           | False        | False         | True          | False              | False           | False         | False          | False        | True          | False            |\n",
      "|  4 | 300004 | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 | Grandmaster | Lava Hot | l       | W       | qK      |     4 |      11 | False         | True        | False           | False          | False        | True              | False            | False       | True        | False           | False        | False         | True          | False              | False           | False         | False          | False        | True          | False            |\n"
     ]
    }
   ],
   "source": [
    "# performing dummy encoding on the dataset\n",
    "\n",
    "# make a copy of the dataset\n",
    "data_dummy_encoding = data.copy()\n",
    "\n",
    "# performing dummy encoding on the dataset\n",
    "data_dummy_encoding = pd.get_dummies(data_dummy_encoding, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'], drop_first=True)\n",
    "print(data_dummy_encoding.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id |   nom_0 |   nom_1 |   nom_2 |   nom_3 |   nom_4 | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 | ord_1       | ord_2    | ord_3   | ord_4   | ord_5   |   day |   month |\n",
      "|---:|-------:|--------:|--------:|--------:|--------:|--------:|:----------|:----------|:----------|:----------|:----------|--------:|:------------|:---------|:--------|:--------|:--------|------:|--------:|\n",
      "|  0 | 300000 |       0 |       5 |       0 |       3 |       2 | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 | Novice      | Warm     | j       | P       | be      |     5 |      11 |\n",
      "|  1 | 300001 |       2 |       2 |       4 |       0 |       2 | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 | Master      | Lava Hot | l       | A       | RP      |     7 |       5 |\n",
      "|  2 | 300002 |       0 |       2 |       2 |       1 |       2 | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 | Expert      | Freezing | a       | G       | tP      |     1 |      12 |\n",
      "|  3 | 300003 |       2 |       3 |       1 |       1 |       2 | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 | Contributor | Lava Hot | b       | Q       | ke      |     2 |       3 |\n",
      "|  4 | 300004 |       2 |       4 |       2 |       1 |       2 | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 | Grandmaster | Lava Hot | l       | W       | qK      |     4 |      11 |\n"
     ]
    }
   ],
   "source": [
    "# performing ordinal encoding on the dataset\n",
    "\n",
    "# creating a copy of the dataset\n",
    "data_ordinal_encoding = data.copy()\n",
    "\n",
    "# creating an object of the OrdinalEncoder class\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# performing ordinal encoding on the dataset\n",
    "data_ordinal_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']] = encoder.fit_transform(\n",
    "    data_ordinal_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']])\n",
    "print(  data_ordinal_encoding.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mainp\\AppData\\Local\\Temp\\ipykernel_15068\\3578475438.py:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data_binary_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']] = data_binary_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']].applymap(lambda x: format(x, 'b'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id |   nom_0 |   nom_1 |   nom_2 |   nom_3 |   nom_4 | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 |   day |   month |\n",
      "|---:|-------:|--------:|--------:|--------:|--------:|--------:|:----------|:----------|:----------|:----------|:----------|--------:|------:|--------:|\n",
      "|  0 | 300000 |       0 |       0 |       0 |       0 |       0 | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 |     5 |      11 |\n",
      "|  1 | 300001 |       1 |       1 |       1 |       1 |       0 | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 |     7 |       5 |\n",
      "|  2 | 300002 |       0 |       1 |      10 |      10 |       0 | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 |     1 |      12 |\n",
      "|  3 | 300003 |       1 |      10 |      11 |      10 |       0 | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 |     2 |       3 |\n",
      "|  4 | 300004 |       1 |      11 |      10 |      10 |       0 | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 |     4 |      11 |\n"
     ]
    }
   ],
   "source": [
    "# performing binary encoding on the dataset\n",
    "\n",
    "# make a copy of the dataset\n",
    "data_binary_encoding = data.copy()\n",
    "\n",
    "# mapping\n",
    "mapping = []\n",
    "\n",
    "# creating a list of dictionaries containing the mapping for each column\n",
    "for col in ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']:\n",
    "    unique_values = data_binary_encoding[col].unique()\n",
    "    value_to_int_mapping = {value: idx for idx,\n",
    "                            value in enumerate(unique_values)}\n",
    "    mapping.append({'col': col, 'mapping': value_to_int_mapping})\n",
    "\n",
    "# performing binary encoding on the dataset\n",
    "data_binary_encoding = data_binary_encoding.drop(\n",
    "    ['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5'], axis=1)\n",
    "\n",
    "for col_map in mapping:\n",
    "    data_binary_encoding[col_map['col']] = data_binary_encoding[col_map['col']].map(\n",
    "        col_map['mapping'])\n",
    "\n",
    "\n",
    "# applying binary format on the dataset columns\n",
    "\n",
    "# select the columns to be converted to binary format\n",
    "data_binary_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']] = data_binary_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']].astype(\n",
    "    'category').apply(lambda x: x.cat.codes)\n",
    "\n",
    "data_binary_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']] = data_binary_encoding[['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']].applymap(lambda x: format(x, 'b'))\n",
    "\n",
    "# printing the first 5 rows of the dataset\n",
    "print(data_binary_encoding.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |     id | nom_5     | nom_6     | nom_7     | nom_8     | nom_9     |   ord_0 | ord_1       | ord_2    | ord_3   | ord_4   | ord_5   |   day |   month |   nom_0_count |   nom_1_count |   nom_2_count |   nom_3_count |   nom_4_count |\n",
      "|---:|-------:|:----------|:----------|:----------|:----------|:----------|--------:|:------------|:---------|:--------|:--------|:--------|------:|--------:|--------------:|--------------:|--------------:|--------------:|--------------:|\n",
      "|  0 | 300000 | 0870b0a5d | 9ceb19dd6 | 530f8ecc3 | 9d117320c | 3c49b42b8 |       2 | Novice      | Warm     | j       | P       | be      |     5 |      11 |         63762 |         19835 |         23767 |         25028 |         56491 |\n",
      "|  1 | 300001 | a5c276589 | 1ad744242 | 12e6161c9 | 46ae3059c | 285771075 |       1 | Master      | Lava Hot | l       | A       | RP      |     7 |       5 |         51083 |         33036 |         67665 |         33035 |         56491 |\n",
      "|  2 | 300002 | 568550f04 | 1fe17a1fd | 27d6df03f | b759e21f0 | 6f323c53f |       2 | Expert      | Freezing | a       | G       | tP      |     1 |      12 |         63762 |         33036 |         24922 |         30552 |         56491 |\n",
      "|  3 | 300003 | c5725677e | a6542cec0 | 30c63bd0c | 0b6ec68ff | b5de3dcc4 |       1 | Contributor | Lava Hot | b       | Q       | ke      |     2 |       3 |         51083 |         30772 |         33230 |         30552 |         56491 |\n",
      "|  4 | 300004 | e70a6270d | 97b6a3518 | a42386065 | f91f3b1ee | 967cfa9c9 |       3 | Grandmaster | Lava Hot | l       | W       | qK      |     4 |      11 |         51083 |         67250 |         24922 |         30552 |         56491 |\n"
     ]
    }
   ],
   "source": [
    "# performing count encoding on the dataset\n",
    "\n",
    "# creating a copy of the datatset\n",
    "data_count_encoding = data.copy()\n",
    "\n",
    "for col in ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']:\n",
    "    count_map = data_count_encoding[col].value_counts().to_dict()\n",
    "    data_count_encoding[col +\n",
    "                        '_count'] = data_count_encoding[col].map(count_map)\n",
    "data_count_encoding.drop(\n",
    "    columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'], inplace=True)\n",
    "print(data_count_encoding.head().to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
