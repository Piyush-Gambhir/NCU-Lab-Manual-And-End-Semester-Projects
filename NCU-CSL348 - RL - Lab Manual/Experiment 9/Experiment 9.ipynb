{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Monte Carlo Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes\n",
      "Episode:1\n",
      "State A: Reward 3\n",
      "State A: Reward 2\n",
      "State B: Reward -4\n",
      "State A: Reward 4\n",
      "State B: Reward -3\n",
      "\n",
      "Episode:2\n",
      "State B: Reward -2\n",
      "State A: Reward 3\n",
      "State B: Reward -3\n",
      "\n",
      "Estimated state values:\n",
      "State B: -2.5\n",
      "State A: 1.0\n"
     ]
    }
   ],
   "source": [
    "def monte_carlo_first_visit(episodes):\n",
    "    returns = {}\n",
    "    state_count = {}\n",
    "    state_values = {}\n",
    "\n",
    "    for episode in episodes:\n",
    "        states, rewards = zip(*episode)\n",
    "        total_return = 0\n",
    "\n",
    "        for t in range(len(states) - 1, -1, -1):\n",
    "            state = states[t]\n",
    "            total_return += rewards[t]\n",
    "            if state not in states[:t]:\n",
    "                if state in returns:\n",
    "                    returns[state].append(total_return)\n",
    "                else:\n",
    "                    returns[state] = [total_return]\n",
    "                state_count[state] = len(returns[state])\n",
    "                state_values[state] = sum(returns[state]) / state_count[state]\n",
    "\n",
    "    return state_values\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_episodes = 2\n",
    "    episodes = [\n",
    "        [('A', 3), ('A', 2), ('B', -4), ('A', 4), ('B', -3)],\n",
    "        [('B', -2), ('A', 3), ('B', -3)],\n",
    "    ]\n",
    "\n",
    "    state_values = monte_carlo_first_visit(episodes)\n",
    "\n",
    "    print(\"Episodes\")\n",
    "    i = 0\n",
    "    for episode in episodes:\n",
    "        i += 1\n",
    "        print(\"Episode:\" + str(i))\n",
    "        for state, reward in episode:\n",
    "            print(f\"State {state}: Reward {reward}\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"Estimated state values:\")\n",
    "    for state, value in state_values.items():\n",
    "        print(f\"State {state}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes\n",
      "Episode:1\n",
      "State A: Reward 3\n",
      "State A: Reward 2\n",
      "State B: Reward -4\n",
      "State A: Reward 4\n",
      "State B: Reward -3\n",
      "\n",
      "Episode:2\n",
      "State B: Reward -2\n",
      "State A: Reward 3\n",
      "State B: Reward -3\n",
      "\n",
      "Estimated state values:\n",
      "State A: 0.5\n",
      "State B: -2.75\n"
     ]
    }
   ],
   "source": [
    "gamma = 1.0\n",
    "\n",
    "\n",
    "def calculate_return(episode, t):\n",
    "    G = 0\n",
    "    for i in range(t, len(episode)):\n",
    "        reward = episode[i][1]\n",
    "        G = G + (gamma ** (i - t)) * reward\n",
    "    return G\n",
    "\n",
    "\n",
    "def monte_carlo_every_visit(episodes):\n",
    "    state_values = {}\n",
    "    returns_sum = {}\n",
    "    state_counts = {}\n",
    "\n",
    "    for episode in episodes:\n",
    "        for t in range(len(episode)):\n",
    "            state = episode[t][0]\n",
    "            if state not in state_counts:\n",
    "                state_counts[state] = 0\n",
    "            state_counts[state] += 1\n",
    "\n",
    "            G = calculate_return(episode, t)\n",
    "\n",
    "            if state not in returns_sum:\n",
    "                returns_sum[state] = 0\n",
    "            returns_sum[state] += G\n",
    "\n",
    "            state_values[state] = returns_sum[state] / state_counts[state]\n",
    "\n",
    "    return state_values\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    episodes = [\n",
    "        [('A', 3), ('A', 2), ('B', -4), ('A', 4), ('B', -3)],\n",
    "        [('B', -2), ('A', 3), ('B', -3)],\n",
    "    ]\n",
    "    state_values = monte_carlo_every_visit(episodes)\n",
    "\n",
    "    print(\"Episodes\")\n",
    "    i = 0\n",
    "    for episode in episodes:\n",
    "        i += 1\n",
    "        print(\"Episode:\" + str(i))\n",
    "        for state, reward in episode:\n",
    "            print(f\"State {state}: Reward {reward}\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"Estimated state values:\")\n",
    "    for state, value in state_values.items():\n",
    "        print(f\"State {state}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
