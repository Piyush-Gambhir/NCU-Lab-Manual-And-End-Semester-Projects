{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aba36ca",
   "metadata": {},
   "source": [
    "# **Experiment 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a7146",
   "metadata": {},
   "source": [
    "### Objective\n",
    "Explore Python NLTK and all the text corpora available in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c6c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries from nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Downloading necessary corpora and resources\n",
    "nltk.download(\"punkt\", download_dir=\"C:/nltk_data\")\n",
    "nltk.download(\"stopwords\", download_dir=\"C:/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abe084",
   "metadata": {},
   "source": [
    "### **1. Defining Text Examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1125aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing the PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Defining text examples\n",
    "example_string = '''\n",
    "We get the daily newspaper at our doorstep every morning. The newspaper has many pages and has a great deal of information.\n",
    "We can read about happenings of the previous day or earlier in our city, in the rest of our country and around the world too.\n",
    "It includes topics such as politics, economy, science, environment, business and sports. There is also an interesting children’s section.\n",
    "There are important announcements too that are published in the newspaper. There is something useful and interesting for everyone in the family in the day’s paper.\n",
    "And so we like to read the newspaper.\n",
    "'''\n",
    "\n",
    "worf_quote = '''\n",
    "Price is what you pay, value is what you get. The most important quality for an investor is temperament, not intellect.\n",
    "Remember that the stock market is a manic depressive. The most important investment you can make is in yourself.\n",
    "'''\n",
    "\n",
    "string_for_stemming = '''\n",
    "Viserys assures Rhaenyra she remains his heir and can choose her consort. Meanwhile, brothers Hobert and Otto Hightower secretly scheme to make Aegon the successor, furthering their family's power and prestige.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e985e5c",
   "metadata": {},
   "source": [
    "### **2. Tokenization Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cbce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Example:\n",
      "Tokenized Sentences:  ['\\nWe get the daily newspaper at our doorstep every morning.', 'The newspaper has many pages and has a great deal of information.', 'We can read about happenings of the previous day or earlier in our city, in the rest of our country and around the world too.', 'It includes topics such as politics, economy, science, environment, business and sports.', 'There is also an interesting children’s section.', 'There are important announcements too that are published in the newspaper.', 'There is something useful and interesting for everyone in the family in the day’s paper.', 'And so we like to read the newspaper.']\n",
      "Tokenized Words:  ['We', 'get', 'the', 'daily', 'newspaper', 'at', 'our', 'doorstep', 'every', 'morning', '.', 'The', 'newspaper', 'has', 'many', 'pages', 'and', 'has', 'a', 'great', 'deal', 'of', 'information', '.', 'We', 'can', 'read', 'about', 'happenings', 'of', 'the', 'previous', 'day', 'or', 'earlier', 'in', 'our', 'city', ',', 'in', 'the', 'rest', 'of', 'our', 'country', 'and', 'around', 'the', 'world', 'too', '.', 'It', 'includes', 'topics', 'such', 'as', 'politics', ',', 'economy', ',', 'science', ',', 'environment', ',', 'business', 'and', 'sports', '.', 'There', 'is', 'also', 'an', 'interesting', 'children', '’', 's', 'section', '.', 'There', 'are', 'important', 'announcements', 'too', 'that', 'are', 'published', 'in', 'the', 'newspaper', '.', 'There', 'is', 'something', 'useful', 'and', 'interesting', 'for', 'everyone', 'in', 'the', 'family', 'in', 'the', 'day', '’', 's', 'paper', '.', 'And', 'so', 'we', 'like', 'to', 'read', 'the', 'newspaper', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenization Example\n",
    "def tokenize_text(text):\n",
    "    print(\"Tokenized Sentences: \", sent_tokenize(text))\n",
    "    print(\"Tokenized Words: \", word_tokenize(text))\n",
    "\n",
    "# Display tokenization results\n",
    "print(\"Tokenization Example:\")\n",
    "tokenize_text(example_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6652e05",
   "metadata": {},
   "source": [
    "### **3. Removing Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ef1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words Removal Example:\n",
      "Filtered Words:  ['Price', 'pay', ',', 'value', 'get', '.', 'important', 'quality', 'investor', 'temperament', ',', 'intellect', '.', 'Remember', 'stock', 'market', 'manic', 'depressive', '.', 'important', 'investment', 'make', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Removing Stop Words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words_in_quote = word_tokenize(text)\n",
    "    filtered_list = [word for word in words_in_quote if word.casefold() not in stop_words]\n",
    "    return filtered_list\n",
    "\n",
    "# Display results after removing stop words\n",
    "print(\"Stop Words Removal Example:\")\n",
    "filtered_words = remove_stopwords(worf_quote)\n",
    "print(\"Filtered Words: \", filtered_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db3f24",
   "metadata": {},
   "source": [
    "### **4. Stemming Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc9713e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming Example:\n",
      "Stemmed Words:  ['viseri', 'assur', 'rhaenyra', 'she', 'remain', 'hi', 'heir', 'and', 'can', 'choos', 'her', 'consort', '.', 'meanwhil', ',', 'brother', 'hobert', 'and', 'otto', 'hightow', 'secretli', 'scheme', 'to', 'make', 'aegon', 'the', 'successor', ',', 'further', 'their', 'famili', \"'s\", 'power', 'and', 'prestig', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stemming Example\n",
    "def perform_stemming(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return stemmed_words\n",
    "\n",
    "# Display stemming results\n",
    "print(\"Stemming Example:\")\n",
    "stemmed_output = perform_stemming(string_for_stemming)\n",
    "print(\"Stemmed Words: \", stemmed_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
